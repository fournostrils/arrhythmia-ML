import wfdb
import pandas as pd
import numpy as np
from scipy.signal import medfilt, find_peaks, butter, lfilter
import matplotlib.pyplot as plt

# Function to save ECG data to CSV
def save_ecg_to_csv(record_name):
    # Read ECG record
    record = wfdb.rdrecord(record_name, pn_dir='mitdb')

    # Extract signal data
    ecg_data = record.p_signal
    lead_names = record.sig_name

    # Calculate time information based on sampling frequency
    sampling_frequency = record.fs  # Sampling frequency in samples per second
    num_samples = len(ecg_data)    # Total number of samples
    time = 1/sampling_frequency * np.arange(0,num_samples)

    # Create a DataFrame to store stuff
    df = pd.DataFrame(columns=['Time']+lead_names)
    df[lead_names] = ecg_data
    df['Time'] = time

################# median filter ###################
    baseline = medfilt(df[lead_names[0]], 71)       #cite the guy for this
    baseline = medfilt(baseline, 215)
    df[lead_names[0]] = df[lead_names[0]]-np.asfarray(baseline)
###################################################

############### bandpass filter ###################
    highcut = 15
    lowcut = .5

    nyq = 0.5 * sampling_frequency
    low = lowcut / nyq
    high = highcut / nyq
    b, a = butter(5, [low, high], btype='band')
    df[lead_names[0]] = lfilter(b, a, df[lead_names[0]])
####################################################

################# median filter ###################
    baseline = medfilt(df[lead_names[0]], 71)       #cite the guy for this
    baseline = medfilt(baseline, 215)
    df[lead_names[0]] = df[lead_names[0]]-np.asfarray(baseline)
###################################################

################### moving window integrations ######################
    def moving_window(data, window_size):
        window = np.ones(window_size) / window_size
        integrated_signal = np.convolve(data, window, mode='same')
        return integrated_signal
    
    df[lead_names[0]] = moving_window(df[lead_names[0]], 3)
#####################################################################

    # Save DataFrame to CSV file
    filename = f'{record_name}.csv'
    df.to_csv(filename, index=False)
    print(f'Saved {filename}')
    
def feature_extract(record_name):

    data = pd.read_csv(f"C:\\Users\\pharr\\OneDrive\\Desktop\\PYTHON\\{record_name}.csv")
    lead = data.columns[1]

    data['gradient'] = np.gradient(data[lead])        #first derivative peak is very reliably in the middle of the increasing part of the r wave
    r_peaks = find_peaks(np.asfarray(data['gradient']),prominence = 0.3*max(data['gradient']), distance = 72, height=0.25*max(data['gradient']))[0]
    print('1st derivative peaks length:' + str(len(r_peaks)))
    peak_dev1 = r_peaks
    print(peak_dev1)
    
    # Read annotation data
    ann = wfdb.rdann(record_name, 'atr', pn_dir='mitdb')

    # Extract annotation symbols and sample indices
    symbols = ann.symbol
    sample_indices = ann.sample
    #time_points = sample_indices/sampling_frequency

    r_peaks_matched, sample_indices_matched, symbols_matched = [], [], []

    for i in range(len(r_peaks)):
        close = np.isclose(r_peaks[i],sample_indices, atol=50)
        close.tolist()
        if True in close: #has to be really close to ensure that only one True is in the array
            close_indices = np.where(close)[0][0]
            r_peaks_matched.append(r_peaks[i])
            sample_indices_matched.append(sample_indices[close_indices])
            symbols_matched.append(symbols[close_indices])

    # should return arrays with same values
    
    output_x = []
    output_y = []
    output_indices = []
    output_test = pd.DataFrame(columns = ['index1','index2','rr_post', 'rp_dist', 'rq_dist', 'rs_dist','rt_dist','rp_ratio', 'rq_ratio', 'rs_ratio', 'rt_ratio'])
    
    for i in range(len(r_peaks_matched)-1):
        #find r-r distance between peaks and store in array
        #ask about r-r array being one shorter than other one and how we should deal with that
        rr_post = r_peaks_matched[i+1] - r_peaks_matched[i]
        window = []

        if r_peaks_matched[i] > 90 and r_peaks_matched[i]+90 <len(data):
                window = data[lead][r_peaks_matched[i]-90:r_peaks_matched[i]+90] #window
                ##### calculations #####

                #find locations of wave peaks around r wave
                px, py = np.argmax(window[0:40]), np.max(window[0:40])
                qx,qy = np.argmin(window[75:85]), np.min(window[75:85])
                sx, sy = np.argmin(window[95:105]), np.min(window[95:105])
                tx, ty = np.argmax(window[150:180]), np.max(window[150:180])

                #find distance between r wave and each other wave
                rx,ry = r_peaks[i], data[lead][r_peaks[i]]

                rp_dist, rq_dist, rs_dist, rt_dist = np.sqrt((rx-px)**2 + (ry-py)**2), np.sqrt((rx-qx)**2 + (ry-qy)**2), np.sqrt((rx-sx)**2 + (ry-sy)**2), np.sqrt((rx-tx)**2 + (ry-ty)**2)
                #perhaps make array to store distances; do more research

                #find ratio between heights of r peak and each other peak (p/r)
                rp_ratio = py/ry
                rq_ratio = qy/ry
                rs_ratio = sy/ry
                rt_ratio = ty/ry

                #make array of importnat values for this window
                window_vals = np.array([rr_post, rp_dist, rq_dist, rs_dist, rt_dist, rp_ratio, rq_ratio, rs_ratio, rt_ratio])
                output_x.append(window_vals)

    output_y = symbols_matched
    output_test['index1'] = r_peaks_matched[:len(output_x)]
    output_test['index2'] = sample_indices_matched[:len(output_x)]
    output_test[['rr_post', 'rp_dist', 'rq_dist', 'rs_dist','rt_dist','rp_ratio', 'rq_ratio', 'rs_ratio', 'rt_ratio']]  = output_x
    output_test['notes'] = symbols_matched[:len(output_x)]

    output_test.to_csv('lol.csv', index=False)

    '''
    ######################## plots #########################
    fig, axs = plt.subplots(2, 1, figsize=(10, 5))
    
    #plot fo raw data
    axs[0].plot(data['Time'],data[lead])
    axs[0].plot(data['Time'][r_peaks], data[lead][r_peaks], 'x')
    axs[0].set_title('2nd derivative')
    axs[0].grid(True)
    '''

    #plot of double filtered data
    '''    axs[1].plot(data['Time'],data[lead])
    axs[1].plot(data['Time'][sample_indices], data[lead][sample_indices], 'x')
    axs[1].set_title('annotations')
    axs[1].grid(True)
    plt.tight_layout()
    plt.show()'''

    '''plt.figure()
    plt.plot(data['Time'],data[lead])
    plt.plot(data['Time'][r_peaks_matched], data[lead][r_peaks_matched], 'x')
    plt.plot(data['Time'][sample_indices], data[lead][sample_indices], 'r.')
    plt.title('1st derivative')
    plt.grid(True)

    plt.tight_layout()
    plt.show()'''

    ########################################################
# Example usage
#save_ecg_to_csv('100')
feature_extract('100')


